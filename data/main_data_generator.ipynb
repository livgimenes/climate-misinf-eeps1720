{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import csv\n",
    "import json\n",
    "import pandas as pd\n",
    "import os\n",
    "from datetime import datetime\n",
    "from pytz import timezone\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime\n",
    "import urllib\n",
    "import numpy as np\n",
    "import plotly.graph_objects as go\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2434, 9)\n",
      "(2413, 9)\n",
      "(2423, 9)\n"
     ]
    }
   ],
   "source": [
    "# load the two csv files\n",
    "raw_df = pd.read_csv(\"raw_data/raw_politcal_posts_three.csv\")\n",
    "print(raw_df.shape)\n",
    "\n",
    "\n",
    "raw_df2 = pd.read_csv(\"raw_data/raw_politcal_posts_two.csv\")\n",
    "print(raw_df2.shape)\n",
    "\n",
    "#combine and remove duplicates\n",
    "all_df = pd.concat([raw_df, raw_df2])\n",
    "all_df = all_df.drop_duplicates(subset=['id'])\n",
    "print(all_df.shape)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating the future df to add things to "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "#make a df that has a claim column and if text or title\n",
    "df_one = pd.DataFrame(columns=['claim', 'type', 'subreddit'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0     [It’s, coming, so, we, got, to, be, prepared, ...\n",
      "4     [I, consider, myself, a, believer, in, what, i...\n",
      "6     [Just, like, the, title, says,, I, wonder, why...\n",
      "7     [Do, you, believe, humanity, taking, collectiv...\n",
      "10    [I, hear, in, the, media, on, how, the, climat...\n",
      "Name: selftext, dtype: object\n",
      "(792, 9)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/liviagimenes/cs1951a_venv/lib/python3.7/site-packages/ipykernel_launcher.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  import sys\n"
     ]
    }
   ],
   "source": [
    "# This contains purely text that is good to analyze\n",
    "\n",
    "#drop NaN from selftext\n",
    "text_df = all_df.dropna(subset=['selftext'])\n",
    "\n",
    "#make it into a list and split it by space\n",
    "text_df['selftext'] = text_df['selftext'].apply(lambda x: x.split())\n",
    "\n",
    "\n",
    "print(text_df['selftext'].head())\n",
    "print(text_df.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                               claim  type    subreddit\n",
      "0  [It’s, coming, so, we, got, to, be, prepared, ...  text  Libertarian\n",
      "1  [I, consider, myself, a, believer, in, what, i...  text  Libertarian\n",
      "2  [Just, like, the, title, says,, I, wonder, why...  text  Libertarian\n",
      "3  [Do, you, believe, humanity, taking, collectiv...  text  Libertarian\n",
      "4  [I, hear, in, the, media, on, how, the, climat...  text  Libertarian\n",
      "(792, 3)\n"
     ]
    }
   ],
   "source": [
    "#insert title_list into claim and set all of the type to title\n",
    "for index, row in text_df.iterrows():\n",
    "    df_one = df_one.append({'claim': row['selftext'], 'type': 'text', 'subreddit': row['subreddit']}, ignore_index=True)\n",
    "#drop null rows\n",
    "df_one = df_one.dropna(subset=['claim'])\n",
    "\n",
    "print(df_one.head())\n",
    "print(df_one.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        id    subreddit                                              title  \\\n",
      "0  10w1dj4  Libertarian  What is the Libertarian solution to climate ch...   \n",
      "1    aocqp  Libertarian  Prof Anastasios Tsonis: University of Wisconsi...   \n",
      "2   v65fv1  Libertarian  Three Supreme Court cases to watch beyond abor...   \n",
      "3   voask2  Libertarian  Supreme Court limits EPA’s power to combat cli...   \n",
      "4   uqcz0p  Libertarian  A green libertarian perspective: is bad to hav...   \n",
      "\n",
      "              author                                                url  \\\n",
      "0  ErgonomicSikorsky  https://www.reddit.com/r/Libertarian/comments/...   \n",
      "1          DougDante  http://www.dailymail.co.uk/sciencetech/article...   \n",
      "2           Elranzer  https://www.brennancenter.org/our-work/researc...   \n",
      "3   Careless_Bat2543  https://www.washingtonpost.com/politics/2022/0...   \n",
      "4           cr7fan89  https://www.reddit.com/r/Libertarian/comments/...   \n",
      "\n",
      "                                            selftext  score  num_comments  \\\n",
      "0       It’s coming so we got to be prepared for it.     18           315   \n",
      "1                                                NaN      0             2   \n",
      "2                                                NaN    371           318   \n",
      "3                                                NaN    219           194   \n",
      "4  I consider myself a believer in what is called...    133           468   \n",
      "\n",
      "    created_utc  \n",
      "0  1.675775e+09  \n",
      "1  1.263243e+09  \n",
      "2  1.654527e+09  \n",
      "3  1.656602e+09  \n",
      "4  1.652641e+09  \n",
      "(2254, 9)\n",
      "0       [What, is, the, Libertarian, solution, to, cli...\n",
      "1       [Prof, Anastasios, Tsonis:, University, of, Wi...\n",
      "2       [Three, Supreme, Court, cases, to, watch, beyo...\n",
      "3       [Supreme, Court, limits, EPA’s, power, to, com...\n",
      "4       [A, green, libertarian, perspective:, is, bad,...\n",
      "                              ...                        \n",
      "199     [Why, don't, we, treat, climate, change, with,...\n",
      "499     [Judicial, Watch, files, lawsuit, to, obtain, ...\n",
      "915     [The, Paris, Climate, Agreement, Won't, Change...\n",
      "1187    [Ahead, of, UN, summit,, leading, scientists, ...\n",
      "1632    [Climate, Misanthropes, Say, Fighting, Climate...\n",
      "Name: title, Length: 2254, dtype: object\n",
      "0       [What, is, the, Libertarian, solution, to, cli...\n",
      "1       [Prof, Anastasios, Tsonis:, University, of, Wi...\n",
      "2       [Three, Supreme, Court, cases, to, watch, beyo...\n",
      "3       [Supreme, Court, limits, EPA’s, power, to, com...\n",
      "4       [A, green, libertarian, perspective:, is, bad,...\n",
      "                              ...                        \n",
      "199     [Why, don't, we, treat, climate, change, with,...\n",
      "499     [Judicial, Watch, files, lawsuit, to, obtain, ...\n",
      "915     [The, Paris, Climate, Agreement, Won't, Change...\n",
      "1187    [Ahead, of, UN, summit,, leading, scientists, ...\n",
      "1632    [Climate, Misanthropes, Say, Fighting, Climate...\n",
      "Name: title, Length: 2254, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# this is trying to get titles that might be good to analyze\n",
    "title_df = all_df.dropna(subset=['title'])\n",
    "\n",
    "\n",
    "#drop duplicates\n",
    "title_df = title_df.drop_duplicates(subset=['title'])\n",
    "print(title_df.head())\n",
    "print(title_df.shape)\n",
    "\n",
    "#get all of the titles into a list \n",
    "title_df['title'] = title_df['title'].apply(lambda x: x.split())\n",
    "print(title_df['title'])\n",
    "\n",
    "#filter the list to not include list that have less than 15 words\n",
    "# create boolean mask based on title length\n",
    "mask = title_df['title'].apply(lambda x: len(' '.join(x)) > 15)\n",
    "\n",
    "# filter dataframe based on boolean mask\n",
    "df = title_df[mask]\n",
    "\n",
    "\n",
    "\n",
    "print(title_df['title'])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                               claim   type    subreddit\n",
      "0  [It’s, coming, so, we, got, to, be, prepared, ...  title  Libertarian\n",
      "1  [I, consider, myself, a, believer, in, what, i...  title  Libertarian\n",
      "2  [Just, like, the, title, says,, I, wonder, why...  title  Libertarian\n",
      "3  [Do, you, believe, humanity, taking, collectiv...  title  Libertarian\n",
      "4  [I, hear, in, the, media, on, how, the, climat...  title  Libertarian\n",
      "(792, 3)\n",
      "                                               claim  type    subreddit\n",
      "0  [It’s, coming, so, we, got, to, be, prepared, ...  text  Libertarian\n",
      "1  [I, consider, myself, a, believer, in, what, i...  text  Libertarian\n",
      "2  [Just, like, the, title, says,, I, wonder, why...  text  Libertarian\n",
      "3  [Do, you, believe, humanity, taking, collectiv...  text  Libertarian\n",
      "4  [I, hear, in, the, media, on, how, the, climat...  text  Libertarian\n",
      "(1584, 3)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "df_two = pd.DataFrame(columns=['claim','type',\"subreddit\"])\n",
    "for index, row in text_df.iterrows():\n",
    "    df_two = df_two.append({'claim': row['selftext'], 'type': 'title', 'subreddit': row['subreddit']}, ignore_index=True)\n",
    "df_two = df_two.dropna(subset=['claim'])\n",
    "\n",
    "print(df_two.head())\n",
    "print(df_two.shape)\n",
    "\n",
    "#combine the two df\n",
    "df = pd.concat([df_one, df_two])\n",
    "print(df.head())\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save the data\n",
    "df.to_csv(\"clean/political_posts.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cs1951a_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
