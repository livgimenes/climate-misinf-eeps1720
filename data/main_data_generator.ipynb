{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import csv\n",
    "import json\n",
    "import pandas as pd\n",
    "import os\n",
    "from datetime import datetime\n",
    "from pytz import timezone\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime\n",
    "import urllib\n",
    "import numpy as np\n",
    "import plotly.graph_objects as go\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2434, 9)\n",
      "(2413, 9)\n",
      "(2423, 9)\n"
     ]
    }
   ],
   "source": [
    "# load the two csv files\n",
    "raw_df = pd.read_csv(\"raw_data/raw_politcal_posts_three.csv\")\n",
    "print(raw_df.shape)\n",
    "\n",
    "\n",
    "raw_df2 = pd.read_csv(\"raw_data/raw_politcal_posts_two.csv\")\n",
    "print(raw_df2.shape)\n",
    "\n",
    "#combine and remove duplicates\n",
    "all_df = pd.concat([raw_df, raw_df2])\n",
    "all_df = all_df.drop_duplicates(subset=['id'])\n",
    "print(all_df.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Libertarian' 'Anarchism' 'socialism' 'progressive' 'Conservative'\n",
      " 'americanpirateparty' 'democrats' 'Liberal' 'Republican'\n",
      " 'LibertarianLeft' 'Liberty' 'Anarcho_Capitalism' 'alltheleft' 'neoprogs'\n",
      " 'labor' 'blackflag' 'GreenParty' 'democracy' 'IWW' 'Marxism'\n",
      " 'Objectivism' 'LibertarianSocialism' 'Capitalism' 'feminisms'\n",
      " 'republicans' 'Egalitarianism' 'anarchafeminism' 'SocialDemocracy'\n",
      " 'Postleftanarchism' 'AnarchoPacifism' 'conservatives' 'voluntarism'\n",
      " 'PirateParty' 'Anarchist' 'Communist']\n",
      "35\n"
     ]
    }
   ],
   "source": [
    "# columns subreddit\n",
    "subreddits = all_df['subreddit'].unique()\n",
    "print(subreddits)\n",
    "print(len(subreddits))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Libertarian' 'Anarchist' 'socialism' 'progressive' 'Conservative'\n",
      " 'PirateParty' 'democrats' 'Liberal' 'Republican' 'LibertarianLeft'\n",
      " 'Liberty' 'Anarcho_Capitalism' 'alltheleft' 'neoprogs' 'labor'\n",
      " 'blackflag' 'GreenParty' 'democracy' 'IWW' 'Marxism' 'Objectivism'\n",
      " 'LibertarianSocialism' 'Capitalism' 'feminisms' 'Egalitarianism'\n",
      " 'anarchafeminism' 'SocialDemocracy' 'Postleftanarchism' 'AnarchoPacifism'\n",
      " 'conservatives' 'voluntarism' 'Communist']\n",
      "32\n"
     ]
    }
   ],
   "source": [
    "# Republican, republicans \n",
    "all_df.loc[all_df['subreddit'] == 'republicans', 'subreddit'] = 'Republican'\n",
    "\n",
    "# Anarchism, Anarchist\n",
    "all_df.loc[all_df['subreddit'] == 'Anarchism', 'subreddit'] = 'Anarchist'\n",
    "\n",
    "# americanpirateparty, PirateParty\n",
    "all_df.loc[all_df['subreddit'] == 'americanpirateparty', 'subreddit'] = 'PirateParty'\n",
    "\n",
    "subred_rows = all_df['subreddit'].unique()\n",
    "print(subred_rows)\n",
    "print(len(subred_rows))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conservative            220\n",
      "Libertarian             206\n",
      "Anarcho_Capitalism      204\n",
      "Anarchist               203\n",
      "socialism               202\n",
      "Republican              173\n",
      "conservatives           127\n",
      "democrats               122\n",
      "progressive             115\n",
      "Liberal                 112\n",
      "GreenParty              112\n",
      "alltheleft              111\n",
      "SocialDemocracy          98\n",
      "Capitalism               87\n",
      "Objectivism              60\n",
      "blackflag                47\n",
      "Marxism                  39\n",
      "feminisms                35\n",
      "labor                    32\n",
      "democracy                27\n",
      "LibertarianSocialism     21\n",
      "IWW                      18\n",
      "LibertarianLeft          14\n",
      "Egalitarianism           10\n",
      "Postleftanarchism         6\n",
      "PirateParty               6\n",
      "neoprogs                  5\n",
      "AnarchoPacifism           4\n",
      "Liberty                   3\n",
      "anarchafeminism           2\n",
      "Communist                 1\n",
      "voluntarism               1\n",
      "Name: subreddit, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# generate how many post exist for each subreddit\n",
    "subred_count = all_df['subreddit'].value_counts()\n",
    "print(subred_count)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conservative          220\n",
      "Libertarian           206\n",
      "Anarcho_Capitalism    204\n",
      "Anarchist             203\n",
      "socialism             202\n",
      "Republican            173\n",
      "conservatives         127\n",
      "democrats             122\n",
      "progressive           115\n",
      "Liberal               112\n",
      "GreenParty            112\n",
      "alltheleft            111\n",
      "SocialDemocracy        98\n",
      "Capitalism             87\n",
      "Objectivism            60\n",
      "Name: subreddit, dtype: int64\n",
      "(2152, 9)\n"
     ]
    }
   ],
   "source": [
    "# filter out subreddits with less than 50 posts from the main dataframe\n",
    "all_df = all_df[all_df['subreddit'].isin(subred_count.index[subred_count > 50])]\n",
    "subred_count = subred_count[subred_count > 50]\n",
    "print(subred_count)\n",
    "print(all_df.shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating the future df to add things to "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#make a df that has a claim column and if text or title\n",
    "df_one = pd.DataFrame(columns=['claim', 'type', 'subreddit'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0     [It’s, coming, so, we, got, to, be, prepared, ...\n",
      "4     [I, consider, myself, a, believer, in, what, i...\n",
      "6     [Just, like, the, title, says,, I, wonder, why...\n",
      "7     [Do, you, believe, humanity, taking, collectiv...\n",
      "10    [I, hear, in, the, media, on, how, the, climat...\n",
      "Name: selftext, dtype: object\n",
      "(657, 9)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/liviagimenes/cs1951a_venv/lib/python3.7/site-packages/ipykernel_launcher.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  import sys\n"
     ]
    }
   ],
   "source": [
    "# This contains purely text that is good to analyze\n",
    "\n",
    "#drop NaN from selftext\n",
    "text_df = all_df.dropna(subset=['selftext'])\n",
    "\n",
    "#make it into a list and split it by space\n",
    "text_df['selftext'] = text_df['selftext'].apply(lambda x: x.split())\n",
    "\n",
    "\n",
    "print(text_df['selftext'].head())\n",
    "print(text_df.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                               claim  type    subreddit\n",
      "0  [It’s, coming, so, we, got, to, be, prepared, ...  text  Libertarian\n",
      "1  [I, consider, myself, a, believer, in, what, i...  text  Libertarian\n",
      "2  [Just, like, the, title, says,, I, wonder, why...  text  Libertarian\n",
      "3  [Do, you, believe, humanity, taking, collectiv...  text  Libertarian\n",
      "4  [I, hear, in, the, media, on, how, the, climat...  text  Libertarian\n",
      "(657, 3)\n"
     ]
    }
   ],
   "source": [
    "#insert title_list into claim and set all of the type to title\n",
    "for index, row in text_df.iterrows():\n",
    "    df_one = df_one.append({'claim': row['selftext'], 'type': 'text', 'subreddit': row['subreddit']}, ignore_index=True)\n",
    "#drop null rows\n",
    "df_one = df_one.dropna(subset=['claim'])\n",
    "\n",
    "print(df_one.head())\n",
    "print(df_one.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        id    subreddit                                              title  \\\n",
      "0  10w1dj4  Libertarian  What is the Libertarian solution to climate ch...   \n",
      "1    aocqp  Libertarian  Prof Anastasios Tsonis: University of Wisconsi...   \n",
      "2   v65fv1  Libertarian  Three Supreme Court cases to watch beyond abor...   \n",
      "3   voask2  Libertarian  Supreme Court limits EPA’s power to combat cli...   \n",
      "4   uqcz0p  Libertarian  A green libertarian perspective: is bad to hav...   \n",
      "\n",
      "              author                                                url  \\\n",
      "0  ErgonomicSikorsky  https://www.reddit.com/r/Libertarian/comments/...   \n",
      "1          DougDante  http://www.dailymail.co.uk/sciencetech/article...   \n",
      "2           Elranzer  https://www.brennancenter.org/our-work/researc...   \n",
      "3   Careless_Bat2543  https://www.washingtonpost.com/politics/2022/0...   \n",
      "4           cr7fan89  https://www.reddit.com/r/Libertarian/comments/...   \n",
      "\n",
      "                                            selftext  score  num_comments  \\\n",
      "0       It’s coming so we got to be prepared for it.     18           315   \n",
      "1                                                NaN      0             2   \n",
      "2                                                NaN    371           318   \n",
      "3                                                NaN    219           194   \n",
      "4  I consider myself a believer in what is called...    133           468   \n",
      "\n",
      "    created_utc  \n",
      "0  1.675775e+09  \n",
      "1  1.263243e+09  \n",
      "2  1.654527e+09  \n",
      "3  1.656602e+09  \n",
      "4  1.652641e+09  \n",
      "(2022, 9)\n",
      "0       [What, is, the, Libertarian, solution, to, cli...\n",
      "1       [Prof, Anastasios, Tsonis:, University, of, Wi...\n",
      "2       [Three, Supreme, Court, cases, to, watch, beyo...\n",
      "3       [Supreme, Court, limits, EPA’s, power, to, com...\n",
      "4       [A, green, libertarian, perspective:, is, bad,...\n",
      "                              ...                        \n",
      "499     [Judicial, Watch, files, lawsuit, to, obtain, ...\n",
      "915     [The, Paris, Climate, Agreement, Won't, Change...\n",
      "1015    [Global, climate, change, -, Sobriety, not, au...\n",
      "1187    [Ahead, of, UN, summit,, leading, scientists, ...\n",
      "1632    [Climate, Misanthropes, Say, Fighting, Climate...\n",
      "Name: title, Length: 2022, dtype: object\n",
      "0       [What, is, the, Libertarian, solution, to, cli...\n",
      "1       [Prof, Anastasios, Tsonis:, University, of, Wi...\n",
      "2       [Three, Supreme, Court, cases, to, watch, beyo...\n",
      "3       [Supreme, Court, limits, EPA’s, power, to, com...\n",
      "4       [A, green, libertarian, perspective:, is, bad,...\n",
      "                              ...                        \n",
      "499     [Judicial, Watch, files, lawsuit, to, obtain, ...\n",
      "915     [The, Paris, Climate, Agreement, Won't, Change...\n",
      "1015    [Global, climate, change, -, Sobriety, not, au...\n",
      "1187    [Ahead, of, UN, summit,, leading, scientists, ...\n",
      "1632    [Climate, Misanthropes, Say, Fighting, Climate...\n",
      "Name: title, Length: 2022, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# this is trying to get titles that might be good to analyze\n",
    "title_df = all_df.dropna(subset=['title'])\n",
    "\n",
    "\n",
    "#drop duplicates\n",
    "title_df = title_df.drop_duplicates(subset=['title'])\n",
    "print(title_df.head())\n",
    "print(title_df.shape)\n",
    "\n",
    "#get all of the titles into a list \n",
    "title_df['title'] = title_df['title'].apply(lambda x: x.split())\n",
    "print(title_df['title'])\n",
    "\n",
    "#filter the list to not include list that have less than 15 words\n",
    "# create boolean mask based on title length\n",
    "mask = title_df['title'].apply(lambda x: len(' '.join(x)) > 15)\n",
    "\n",
    "# filter dataframe based on boolean mask\n",
    "df = title_df[mask]\n",
    "\n",
    "\n",
    "\n",
    "print(title_df['title'])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                               claim   type    subreddit\n",
      "0  [It’s, coming, so, we, got, to, be, prepared, ...  title  Libertarian\n",
      "1  [I, consider, myself, a, believer, in, what, i...  title  Libertarian\n",
      "2  [Just, like, the, title, says,, I, wonder, why...  title  Libertarian\n",
      "3  [Do, you, believe, humanity, taking, collectiv...  title  Libertarian\n",
      "4  [I, hear, in, the, media, on, how, the, climat...  title  Libertarian\n",
      "(657, 3)\n",
      "                                               claim  type    subreddit\n",
      "0  [It’s, coming, so, we, got, to, be, prepared, ...  text  Libertarian\n",
      "1  [I, consider, myself, a, believer, in, what, i...  text  Libertarian\n",
      "2  [Just, like, the, title, says,, I, wonder, why...  text  Libertarian\n",
      "3  [Do, you, believe, humanity, taking, collectiv...  text  Libertarian\n",
      "4  [I, hear, in, the, media, on, how, the, climat...  text  Libertarian\n",
      "(1314, 3)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "df_two = pd.DataFrame(columns=['claim','type',\"subreddit\"])\n",
    "for index, row in text_df.iterrows():\n",
    "    df_two = df_two.append({'claim': row['selftext'], 'type': 'title', 'subreddit': row['subreddit']}, ignore_index=True)\n",
    "df_two = df_two.dropna(subset=['claim'])\n",
    "\n",
    "print(df_two.head())\n",
    "print(df_two.shape)\n",
    "\n",
    "#combine the two df\n",
    "df = pd.concat([df_one, df_two])\n",
    "print(df.head())\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save the data\n",
    "df.to_csv(\"clean/political_posts.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cs1951a_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
